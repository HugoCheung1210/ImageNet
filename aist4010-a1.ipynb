{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets,transforms\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport copy\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom math import ceil\n\n\nphi_values = {\"b0\": (0.5, 224, 0.6)}\n\nb_model = [\n    [1, 16, 1, 1, 3],\n    [6, 24, 2, 2, 3],\n    [6, 40, 2, 2, 5],\n    [6, 80, 3, 2, 3],\n    [6, 112, 3, 1, 5],\n    [6, 192, 4, 2, 5],\n    [6, 320, 1, 1, 3],\n]\n\nclass CNNBlk(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel, stride, padding, groups=1):\n        super(CNNBlk, self).__init__()\n        self.cnn = nn.Conv2d(in_channels,out_channels,kernel,stride,padding,groups=groups,bias=False)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.silu = nn.SiLU()  \n\n    def forward(self, x):\n        return self.silu(self.bn(self.cnn(x)))\n\nclass SqueezeExcitation(nn.Module):\n    def __init__(self, in_channels, re_dim):\n        super(SqueezeExcitation, self).__init__()\n        self.se = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1), \n            nn.Conv2d(in_channels, re_dim, 1),\n            nn.SiLU(),\n            nn.Conv2d(re_dim, in_channels, 1),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, x):\n        return x * self.se(x)\n\n# Residue blk\n\nclass Block(nn.Module):\n    def __init__(self,in_channels,out_channels,kernel,stride,padding,expand_ratio,reduction=4,survival_prob=0.8,):\n        super(Block, self).__init__()\n        self.sur_prob = 0.8\n        self.use_res = in_channels == out_channels and stride == 1\n        hid_dim = in_channels * expand_ratio\n        self.expand = in_channels != hid_dim\n        re_dim = int(in_channels / reduction)\n\n        if self.expand:\n            self.expand_conv = CNNBlk(in_channels,hid_dim,kernel=3,stride=1,padding=1)\n\n        self.conv = nn.Sequential(\n            CNNBlk(hid_dim,hid_dim,kernel,stride,padding,groups=hid_dim),\n            SqueezeExcitation(hid_dim, re_dim),\n            nn.Conv2d(hid_dim, out_channels, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n        )\n\n    def s_depth(self, x):\n        if not self.training:\n            return x\n        bin_tensor = (torch.rand(x.shape[0], 1, 1, 1, device=x.device) < self.sur_prob)\n        return torch.div(x, self.sur_prob) * bin_tensor\n\n    def forward(self, inputs):\n        x = self.expand_conv(inputs) if self.expand else inputs\n        if self.use_res:\n            return self.s_depth(self.conv(x)) + inputs\n        else:\n            return self.conv(x)\n        \n# Implementing EfficientNet\nclass Net(nn.Module):\n    def __init__(self, num_classes):\n        super(Net, self).__init__()\n        width, depth, dropout_rate = self.cal()\n        last = ceil(1280 * width)\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.features = self.create_ft(width, depth, last)\n        self.classifier = nn.Sequential(\n            nn.Dropout(dropout_rate),\n            nn.Linear(last, num_classes),\n        )\n\n    def cal(self,alpha=1.2, beta=1.1):\n        phi, res, drop_rate = phi_values['b0']\n        depth = alpha**phi\n        width = beta**phi\n        return width, depth, drop_rate\n\n    def create_ft(self, width, depth, last):\n        channels = int(32 * width)\n        features = [CNNBlk(3, channels, 3, stride=2, padding=1)]\n        in_channels = channels\n\n        for expand_ratio, channels, repeats, stride, kernel in b_model:\n            out_channels = 4 * ceil(int(channels * width) / 4)\n            layers_repeats = ceil(repeats * depth)\n            for layer in range(layers_repeats):\n                features.append(\n                    Block(in_channels,out_channels,expand_ratio=expand_ratio,stride=stride if layer == 0 else 1,kernel=kernel,\n                    padding=kernel // 2, \n                    )\n                )\n                in_channels = out_channels\n\n        features.append(CNNBlk(in_channels, last, kernel=1, stride=1, padding=0))\n        return nn.Sequential(*features)\n    \n    def forward(self, x):\n        x = self.pool(self.features(x))\n        return self.classifier(x.view(x.shape[0], -1))","metadata":{"execution":{"iopub.status.busy":"2023-02-20T16:44:16.861623Z","iopub.execute_input":"2023-02-20T16:44:16.862071Z","iopub.status.idle":"2023-02-20T16:44:16.887760Z","shell.execute_reply.started":"2023-02-20T16:44:16.862031Z","shell.execute_reply":"2023-02-20T16:44:16.886737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomRotation(8),\n        transforms.ColorJitter(.2,.2,.2),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomGrayscale(p=0.1),\n#         transforms.RandomVerticalFlip(p=0.5),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ]),\n    'val': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n}\n\n# def balance_classes(images, classes):\n#     count_per_class = [0] * classes\n#     for _, image_class in images:\n#         count_per_class[image_class] += 1\n#     weight_per_class = [0.] * classes\n#     for i in range(classes):\n#         weight_per_class[i] = 1 / float(count_per_class[i])\n#     return weight_per_class\n\n\ndata_dir = '/kaggle/input/aist4010-spring2023-a1/data/'\n\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir,x ),data_transforms[x]) for x in ['train', 'val']}\n# weights = {x: balance_classes(image_datasets[x].imgs, len(image_datasets[x].classes)) for x in ['train', 'val']}                                                                \n# weights = {x: torch.DoubleTensor(weights[x]) for x in ['train', 'val']} \ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n\n# sampler = {x: torch.utils.data.sampler.WeightedRandomSampler(weights[x], 6000) for x in ['train', 'val']}\n\n# dataloaders = {x: DataLoader(image_datasets[x],batch_size=4,sampler=sampler[x],num_workers=2) for x in ['train', 'val']}\ndataloaders = {x: DataLoader(image_datasets[x],batch_size=96,shuffle=True,num_workers=2) for x in ['train', 'val']}\n\nclass_names = image_datasets['train'].classes\nif torch.cuda.is_available(): \n     device = \"cuda\" \nelse: \n     device = \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2023-02-20T16:44:16.891470Z","iopub.execute_input":"2023-02-20T16:44:16.892633Z","iopub.status.idle":"2023-02-20T16:44:18.302636Z","shell.execute_reply.started":"2023-02-20T16:44:16.892596Z","shell.execute_reply":"2023-02-20T16:44:18.301651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class EarlyStopper:\n#     def __init__(self, patience=1, min_delta=0):\n#         self.patience = patience\n#         self.min_delta = min_delta\n#         self.counter = 0\n#         self.min_validation_loss = np.inf\n\n#     def early_stop(self, validation_loss):\n#         if validation_loss < self.min_validation_loss:\n#             self.min_validation_loss = validation_loss\n#             self.counter = 0\n#         elif validation_loss > (self.min_validation_loss + self.min_delta):\n#             self.counter += 1\n#             if self.counter >= self.patience:\n#                 return True\n#         return False","metadata":{"execution":{"iopub.status.busy":"2023-02-20T16:44:18.304157Z","iopub.execute_input":"2023-02-20T16:44:18.304765Z","iopub.status.idle":"2023-02-20T16:44:18.309804Z","shell.execute_reply.started":"2023-02-20T16:44:18.304728Z","shell.execute_reply":"2023-02-20T16:44:18.308551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer,scheduler, num_epochs=10):\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch+1}/{num_epochs}')\n        print('-' * 10)\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train() \n            else:\n                model.eval()   \n\n            running_loss = 0.0\n            running_corrects = 0\n            correct = 0\n            total = 0\n            for inputs, labels in dataloaders[phase]:   \n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                optimizer.zero_grad()\n    \n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs.data, 1)\n                    loss = criterion(outputs, labels)\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                    total += labels.size(0)\n                    correct += (preds == labels).sum().item()\n                epoch_acc = correct / total\n                running_loss += loss.item() * inputs.size(0)\n                \n            if phase =='train':\n                scheduler.step()\n                \n            epoch_loss = running_loss / dataset_sizes[phase]\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n                \n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n    \n        print()\n        \n    print(f'Best val Acc: {best_acc:4f}')\n\n    torch.save(best_model_wts, \"./trained_res.pt\")\n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-02-20T16:44:18.312219Z","iopub.execute_input":"2023-02-20T16:44:18.312628Z","iopub.status.idle":"2023-02-20T16:44:18.326217Z","shell.execute_reply.started":"2023-02-20T16:44:18.312593Z","shell.execute_reply":"2023-02-20T16:44:18.325219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':            \n    model_ft = Net(num_classes=1000)\n    model_ft = model_ft.to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.1, momentum = 0.9)\n    lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size = 20, gamma=0.2)\n    model_eff = train_model(model_ft, criterion, optimizer_ft, lr_scheduler, num_epochs=80)\n    \n    folder = '/kaggle/input/aist4010-spring2023-a1/data/test'\n    transform = transforms.Compose([transforms.Resize((224, 224)),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n    \n    id_list = []\n    pred_list = []\n    label = []\n    idx_to_class = {v:k for k, v in image_datasets['train'].class_to_idx.items()}\n    with torch.no_grad():\n        for filename in os.listdir(folder):\n            img = Image.open((os.path.join(folder,filename)))\n            image = img.convert(\"RGB\")\n            tensor = transform(img)\n            tensor = tensor.cuda()\n            tensor = tensor.unsqueeze(0)\n            prediction = model_eff(tensor)\n            _, predicted = torch.max(prediction.data, 1)\n            label = idx_to_class[predicted.cpu().numpy()[0]]\n            pred_list.append(label)\n            id_list.append(filename)\n    data = {\"id\":id_list, \"label\":pred_list}\n    df = pd.DataFrame(data)\n    df.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-02-20T16:44:18.329496Z","iopub.execute_input":"2023-02-20T16:44:18.329827Z","iopub.status.idle":"2023-02-20T19:39:32.362062Z","shell.execute_reply.started":"2023-02-20T16:44:18.329801Z","shell.execute_reply":"2023-02-20T19:39:32.360936Z"},"trusted":true},"execution_count":null,"outputs":[]}]}